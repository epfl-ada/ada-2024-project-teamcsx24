{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the use of **topic modeling** on a dataset of movie summaries. The goal is to identify and group recurring themes across the summaries, providing a deeper understanding of the dataset's structure.\n",
    "  \n",
    "To achieve this, we will use **BERTopic**, a powerful topic modeling tool that leverages text embeddings, dimensionality reduction, and density-based clustering to extract interpretable topics from text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnau\\OneDrive\\Documents\\Scolarité EPFL\\ADA\\ada-2024-project-teamcsx24\\src\\models\\../data\\dataLoader.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[columns_to_convert] = df[columns_to_convert].applymap(eval)\n"
     ]
    }
   ],
   "source": [
    "# Modules to import\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths to add\n",
    "paths = ['../data','../scripts','../utils']\n",
    "for path in paths:\n",
    "    sys.path.append(path)\n",
    "    \n",
    "# Data loader\n",
    "from dataLoader import loadDataframe\n",
    "\n",
    "# Load data\n",
    "path_to_directory = '../../data/cleanData/'\n",
    "df_movies = loadDataframe('movies', path_to_directory)\n",
    "df_summaries = loadDataframe('summaries', path_to_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to preprocess the text data. Indeed, summaries contain lot of noise and irrelevant terms such as \"the\", \"a\", etc. We need to clean the text data before feeding it to the model.\n",
    " \n",
    "1. **Lowercasing**: Converting text to lowercase to ensure uniformity.  \n",
    "2. **Tokenization**: Breaking down sentences into individual tokens or words.  \n",
    "3. **Stopword Removal**: Eliminating common words like \"the\" and \"and\" that do not contribute to meaning.  \n",
    "4. **Punctuation Removal**: Stripping away symbols and punctuation marks.  \n",
    "5. **Lemmatization**: Reducing words to their root forms (e.g., \"running\" → \"run\").  \n",
    "6. **Custom Filtering**: Removing domain-specific terms like \"film\" and \"movie,\" which are too general to provide meaningful insights.  \n",
    "\n",
    "We use **spaCy** for tokenization and lemmatization, while **NLTK** provides the list of stopwords for removal. This step ensures the data is clean, compact, and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arnau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arnau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load the spaCy model for English language\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Download stopwords and punkt tokenizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the English stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our own preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Tokenisation\n",
    "    doc = nlp(text.lower())  # Convert to lowercase\n",
    "    \n",
    "    # Lemmatisation and remove stopwords and punctuation\n",
    "    processed_tokens = [\n",
    "        token.lemma_ for token in doc if token.text not in stop_words and token.text not in string.punctuation\n",
    "    ]\n",
    "    \n",
    "    char_to_remove = [\"'s\", \" \"]\n",
    "    processed_tokens = [token for token in processed_tokens if token not in char_to_remove]\n",
    "    \n",
    "    word_to_remove = ['film','movie','story','tell','leave']\n",
    "    processed_tokens = [token for token in processed_tokens if token not in word_to_remove]\n",
    "    \n",
    "    return \" \".join(processed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the preprocessing to each summary of movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42303 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42303/42303 [1:20:13<00:00,  8.79it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Apply the preprocessing to the summaries\n",
    "tqdm.pandas()\n",
    "df_cleaned_summaries = df_summaries.copy()\n",
    "df_cleaned_summaries[\"cleaned_summary\"] = df_cleaned_summaries[\"summary\"].progress_apply(preprocess_text)\n",
    "\n",
    "# Drop the original summary column\n",
    "df_cleaned_summaries.drop(columns=[\"summary\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset contains summaries in multiple languages, we use the **langdetect** library to identify the language of each summary.  \n",
    "- Summaries not in English are either removed or translated (in this notebook, we choose to remove them).  \n",
    "- This ensures the modeling process focuses solely on English text, leading to more consistent and interpretable results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42303/42303 [19:08<00:00, 36.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Detect the language of each summary\n",
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "df_cleaned_summaries[\"language\"] = df_cleaned_summaries[\"cleaned_summary\"].progress_apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned summaries\n",
    "df_cleaned_summaries.to_csv(\"../../data/cultureData/topicModelData/cleaned_summaries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned summaries\n",
    "# df_cleaned_summaries = pd.read_csv(\"../../data/cultureData/topicModelData/cleaned_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage of summaries in English: 99.46%\n"
     ]
    }
   ],
   "source": [
    "pourcentage_english = df_cleaned_summaries[\"language\"].value_counts(normalize=True)[\"en\"] * 100\n",
    "print('Pourcentage of summaries in English: {:.2f}%'.format(pourcentage_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the summaries in English\n",
    "df_cleaned_summaries = df_cleaned_summaries[df_cleaned_summaries[\"language\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) BERTopic Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_cleaned_summaries[\"cleaned_summary\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnau\\anaconda3\\envs\\ada\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Embedding\n",
    "\n",
    "To represent the summaries numerically, we generate embeddings using the **SentenceTransformer** library and the **all-MiniLM-L6-v2** model.  \n",
    "- **Text embeddings**: High-dimensional vectors that capture semantic meaning from text.  \n",
    "- These embeddings allow the model to group similar summaries based on their meanings, rather than just their words.  \n",
    "\n",
    "The generated embeddings are saved to disk to streamline the workflow and avoid recalculating them in subsequent runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1315/1315 [42:35<00:00,  1.94s/it] \n"
     ]
    }
   ],
   "source": [
    "# Embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode the summaries\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "np.save(\"embeddings.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings\n",
    "# embeddings_model = np.load(\"embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. UMAP\n",
    "\n",
    "Text embeddings are often high-dimensional (e.g., 384 dimensions for the chosen transformer model). To make the clustering step more efficient, we reduce their dimensionality using **UMAP** (Uniform Manifold Approximation and Projection).  \n",
    "- UMAP preserves the structure of the data while compressing it into a smaller number of dimensions (e.g., 5).  \n",
    "- This step not only speeds up clustering but also enhances the interpretability of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. HDBSCAN\n",
    "\n",
    "We cluster the reduced embeddings using **HDBSCAN**, a density-based clustering algorithm.  \n",
    "- **Advantages of HDBSCAN**:\n",
    "  - Automatically detects clusters of various sizes and shapes.  \n",
    "  - Identifies and labels outliers (noise points) that do not belong to any cluster.  \n",
    "- This step assigns a cluster ID to each summary, which corresponds to a potential topic.  \n",
    "\n",
    "Clusters identified in this step form the basis for the topics generated by BERTopic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(min_cluster_size=50, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vectorizer\n",
    "\n",
    "While embeddings capture the meaning of the text, traditional **bag-of-words** approaches are useful for understanding the content of each cluster. We use the **CountVectorizer** from scikit-learn to:\n",
    "- Generate term frequencies within each cluster.  \n",
    "- Consider both unigrams (single words) and bigrams (pairs of words) for better topic descriptions.  \n",
    "\n",
    "This textual representation complements the embeddings by enabling interpretable topic names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) BERTopic Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integrate the components (embeddings, UMAP, HDBSCAN, and CountVectorizer) into a single **BERTopic** model.  \n",
    "- The model is trained on the cleaned summaries to identify underlying topics.  \n",
    "- For each summary, BERTopic assigns:\n",
    "  1. A **topic ID**.\n",
    "  2. A probability score indicating the confidence of the assignment.  \n",
    "\n",
    "The trained model is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 20:49:24,887 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 1315/1315 [16:42:18<00:00, 45.73s/it]       \n",
      "2024-11-27 13:31:50,447 - BERTopic - Embedding - Completed ✓\n",
      "2024-11-27 13:31:50,450 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-11-27 13:33:40,868 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-11-27 13:33:40,881 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-11-27 13:34:07,625 - BERTopic - Cluster - Completed ✓\n",
      "2024-11-27 13:34:07,634 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-11-27 13:34:37,968 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "topic_model = BERTopic(embedding_model=embedding_model,\n",
    "                       umap_model=umap_model,\n",
    "                       hdbscan_model=hdbscan_model,\n",
    "                       vectorizer_model=vectorizer_model,\n",
    "                       verbose=True)\n",
    "\n",
    "# Fit the model\n",
    "topics, probabilities = topic_model.fit_transform(docs)\n",
    "df_cleaned_summaries['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:34:43,258 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "topic_model.save(\"topic_model_min_cluster_size_50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try different values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Review Topics\n",
    "\n",
    "Once topics are generated, we refine them to improve their quality:\n",
    "1. **Merging similar topics**: Topics with overlapping themes are combined into a single, more coherent topic.  \n",
    "2. **Dropping non-informative topics**: Topics with low interpretability or relevance are removed.  \n",
    "3. **Assigning meaningful labels**: Descriptive names are given to each topic based on their most frequent words.  \n",
    "\n",
    "This step ensures that the final topics are both informative and easy to understand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_summaries =  pd.read_csv(\"../../data/cultureData/topicModelData/cleaned_summaries.csv\")\n",
    "\n",
    "# Keep only the summaries in English\n",
    "df_cleaned_summaries = df_cleaned_summaries[df_cleaned_summaries[\"language\"] == \"en\"]\n",
    "\n",
    "docs = df_cleaned_summaries[\"cleaned_summary\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new model\n",
    "topic_model = BERTopic.load(\"topic_model_min_cluster_size_50\")\n",
    "topic_info = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics to merge\n",
    "\n",
    "topics_to_merge = [0,2] # love and family\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "\n",
    "topics_to_merge = [16,18] # nazi germany\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "\n",
    "topics_to_merge = [10, 18] # French culture\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "\n",
    "topics_to_merge = [16,26] # pirates\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "\n",
    "topics_to_merge = [7,10] # spain\n",
    "topic_model.merge_topics(docs, topics_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>20926</td>\n",
       "      <td>-1_man_kill_make_try</td>\n",
       "      <td>[man, kill, make, try, time, life, friend, new...</td>\n",
       "      <td>[backwoodsman name adam pontipee new bride mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7433</td>\n",
       "      <td>0_love_father_family_marry</td>\n",
       "      <td>[love, father, family, marry, life, son, come,...</td>\n",
       "      <td>[young widow commit suicide compel forego mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>1_kill_man_house_make</td>\n",
       "      <td>[kill, man, house, make, car, try, police, hom...</td>\n",
       "      <td>[open michelle mancini drive night storm reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1384</td>\n",
       "      <td>2_murder_police_detective_crime</td>\n",
       "      <td>[murder, police, detective, crime, killer, pri...</td>\n",
       "      <td>[psychotic killer garland red lynch use campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>3_ho_li_master_man</td>\n",
       "      <td>[ho, li, master, man, china, wong, kill, chine...</td>\n",
       "      <td>[plot|date\"farewell concubine study notes\"&gt;{{c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>673</td>\n",
       "      <td>4_juan_family_miguel_love</td>\n",
       "      <td>[juan, family, miguel, love, father, man, luis...</td>\n",
       "      <td>[juan oliver want make good impression new job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>638</td>\n",
       "      <td>5_earth_scientist_planet_human</td>\n",
       "      <td>[earth, scientist, planet, human, alien, space...</td>\n",
       "      <td>[distant future war human race alien know gami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>477</td>\n",
       "      <td>6_confederate_town_union_man</td>\n",
       "      <td>[confederate, town, union, man, war, sheriff, ...</td>\n",
       "      <td>[set state virginia american civil war james s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>396</td>\n",
       "      <td>7_jean_paris_pierre_marie</td>\n",
       "      <td>[jean, paris, pierre, marie, love, julien, ant...</td>\n",
       "      <td>[\" feel go life like american tourist many tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>8_german_nazi_hitler_war</td>\n",
       "      <td>[german, nazi, hitler, war, berlin, germany, v...</td>\n",
       "      <td>[world war ii wehrmacht colonel claus von stau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>352</td>\n",
       "      <td>9_earth_ship_planet_alien</td>\n",
       "      <td>[earth, ship, planet, alien, space, human, cre...</td>\n",
       "      <td>[commercial tow spaceship nostromo return trip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>286</td>\n",
       "      <td>10_ship_pirate_island_boat</td>\n",
       "      <td>[ship, pirate, island, boat, captain, shark, c...</td>\n",
       "      <td>[plot jim hawkins young boy live mother englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>227</td>\n",
       "      <td>11_ivan_russian_soviet_moscow</td>\n",
       "      <td>[ivan, russian, soviet, moscow, alexei, russia...</td>\n",
       "      <td>[begin main character ivan yermakov interview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>224</td>\n",
       "      <td>12_soldier_man_order_officer</td>\n",
       "      <td>[soldier, man, order, officer, command, submar...</td>\n",
       "      <td>[plot begin summary ally struggle stop u boat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>219</td>\n",
       "      <td>13_bug_daffy_elmer_porky</td>\n",
       "      <td>[bug, daffy, elmer, porky, duck, rabbit, carto...</td>\n",
       "      <td>[hollywood home bug bunny interview tv show pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>217</td>\n",
       "      <td>14_vampire_ghost_group_werewolf</td>\n",
       "      <td>[vampire, ghost, group, werewolf, daninsky, bl...</td>\n",
       "      <td>[knockabout english comedy spoof hammer series...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>211</td>\n",
       "      <td>15_team_game_player_coach</td>\n",
       "      <td>[team, game, player, coach, play, baseball, le...</td>\n",
       "      <td>[chronicle journey 1980 us olympic men ice hoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>181</td>\n",
       "      <td>16_samurai_rider_keroro_kill</td>\n",
       "      <td>[samurai, rider, keroro, kill, sakura, attack,...</td>\n",
       "      <td>[april 1 2011 kaman rider ooo find battle thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>17_tom_jerry_spike_mouse</td>\n",
       "      <td>[tom, jerry, spike, mouse, cat, run, tail, gra...</td>\n",
       "      <td>[tom acquire book catch mice rest cartoon take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>18_prince_king_arthur_princess</td>\n",
       "      <td>[prince, king, arthur, princess, queen, robin,...</td>\n",
       "      <td>[follow cinderella beautiful girl force chore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>150</td>\n",
       "      <td>19_santa_christmas_scrooge_claus</td>\n",
       "      <td>[santa, christmas, scrooge, claus, santa claus...</td>\n",
       "      <td>[eight year go since divorce father scott calv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>146</td>\n",
       "      <td>20_stooge_moe_curly_shemp</td>\n",
       "      <td>[stooge, moe, curly, shemp, larry, moe larry, ...</td>\n",
       "      <td>[stooge janitor doctor office work night shift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>134</td>\n",
       "      <td>21_african_africa_south_xan</td>\n",
       "      <td>[african, africa, south, xan, apartheid, mande...</td>\n",
       "      <td>[follow news depict demolition slum east londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>108</td>\n",
       "      <td>22_charlie_charlie brown_brown_snoopy</td>\n",
       "      <td>[charlie, charlie brown, brown, snoopy, charle...</td>\n",
       "      <td>[special begin charlie brown sit bench lunch t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>104</td>\n",
       "      <td>23_israeli_israel_palestinian_ashraf</td>\n",
       "      <td>[israeli, israel, palestinian, ashraf, war, je...</td>\n",
       "      <td>[noam young israeli reservist work checkpoint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>97</td>\n",
       "      <td>24_college_school_sorority_student</td>\n",
       "      <td>[college, school, sorority, student, high scho...</td>\n",
       "      <td>[set college u.s.a center jake embittered ex h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>25_donald_mickey_pluto_pete</td>\n",
       "      <td>[donald, mickey, pluto, pete, minnie, goofy, d...</td>\n",
       "      <td>[black pete walk camp inspect hmm camp sure pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>26_kenji_itsuki_yumi_tokyo</td>\n",
       "      <td>[kenji, itsuki, yumi, tokyo, school, kyoko, to...</td>\n",
       "      <td>[hiroko watanabe live kobe lose fiancé itsuki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>85</td>\n",
       "      <td>27_dragon_king_sword_kill</td>\n",
       "      <td>[dragon, king, sword, kill, fantaghirò, prince...</td>\n",
       "      <td>[take place forest sidhe follow princess alora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>84</td>\n",
       "      <td>28_panther_pink_pink panther_horse</td>\n",
       "      <td>[panther, pink, pink panther, horse, man, litt...</td>\n",
       "      <td>[pink panther set camp night serve dish contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>29_yakuza_tokyo_japan_father</td>\n",
       "      <td>[yakuza, tokyo, japan, father, kojima, tsuda, ...</td>\n",
       "      <td>[follow life kazama family tokyo 30th year shō...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>30_tarzan_jane_jungle_africa</td>\n",
       "      <td>[tarzan, jane, jungle, africa, animal, ape, go...</td>\n",
       "      <td>[open flashback tarzan ape establish back afri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>77</td>\n",
       "      <td>31_race_car_herbie_racing</td>\n",
       "      <td>[race, car, herbie, racing, racer, win, driver...</td>\n",
       "      <td>[stars dean jones return champion race car dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>32_artagnan_musketeer_athos_louis</td>\n",
       "      <td>[artagnan, musketeer, athos, louis, king, rich...</td>\n",
       "      <td>[d'artagnan inexperienced gascon youth travel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>69</td>\n",
       "      <td>33_ollie_stan_stan ollie_hardy</td>\n",
       "      <td>[ollie, stan, stan ollie, hardy, laurel, laure...</td>\n",
       "      <td>[stan ollie last six buck call lift job agency...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>34_betty_bimbo_boop_betty boop</td>\n",
       "      <td>[betty, bimbo, boop, betty boop, grampy, betty...</td>\n",
       "      <td>[bimbo show betty door assistant help betty mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>54</td>\n",
       "      <td>35_godzilla_goku_gohan_monster</td>\n",
       "      <td>[godzilla, goku, gohan, monster, vegeta, picco...</td>\n",
       "      <td>[1992 united nations establish united nations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>36_caesar_rome_roman_marcellus</td>\n",
       "      <td>[caesar, rome, roman, marcellus, cleopatra, ca...</td>\n",
       "      <td>[open 48 b.c shortly battle pharsalus julius c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>37_president_bush_nixon_kennedy</td>\n",
       "      <td>[president, bush, nixon, kennedy, campaign, fr...</td>\n",
       "      <td>[series news report document role richard nixo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38_school_teacher_student_pupil</td>\n",
       "      <td>[school, teacher, student, pupil, education, h...</td>\n",
       "      <td>[set danish boy boarding school one boy bo dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>39_rocky_fight_tommy_match</td>\n",
       "      <td>[rocky, fight, tommy, match, boxing, fighter, ...</td>\n",
       "      <td>[four half year since win world heavyweight ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                   Name  \\\n",
       "0      -1  20926                   -1_man_kill_make_try   \n",
       "1       0   7433             0_love_father_family_marry   \n",
       "2       1   4606                  1_kill_man_house_make   \n",
       "3       2   1384        2_murder_police_detective_crime   \n",
       "4       3   1165                     3_ho_li_master_man   \n",
       "5       4    673              4_juan_family_miguel_love   \n",
       "6       5    638         5_earth_scientist_planet_human   \n",
       "7       6    477           6_confederate_town_union_man   \n",
       "8       7    396              7_jean_paris_pierre_marie   \n",
       "9       8    356               8_german_nazi_hitler_war   \n",
       "10      9    352              9_earth_ship_planet_alien   \n",
       "11     10    286             10_ship_pirate_island_boat   \n",
       "12     11    227          11_ivan_russian_soviet_moscow   \n",
       "13     12    224           12_soldier_man_order_officer   \n",
       "14     13    219               13_bug_daffy_elmer_porky   \n",
       "15     14    217        14_vampire_ghost_group_werewolf   \n",
       "16     15    211              15_team_game_player_coach   \n",
       "17     16    181           16_samurai_rider_keroro_kill   \n",
       "18     17    158               17_tom_jerry_spike_mouse   \n",
       "19     18    152         18_prince_king_arthur_princess   \n",
       "20     19    150       19_santa_christmas_scrooge_claus   \n",
       "21     20    146              20_stooge_moe_curly_shemp   \n",
       "22     21    134            21_african_africa_south_xan   \n",
       "23     22    108  22_charlie_charlie brown_brown_snoopy   \n",
       "24     23    104   23_israeli_israel_palestinian_ashraf   \n",
       "25     24     97     24_college_school_sorority_student   \n",
       "26     25     92            25_donald_mickey_pluto_pete   \n",
       "27     26     91             26_kenji_itsuki_yumi_tokyo   \n",
       "28     27     85              27_dragon_king_sword_kill   \n",
       "29     28     84     28_panther_pink_pink panther_horse   \n",
       "30     29     83           29_yakuza_tokyo_japan_father   \n",
       "31     30     80           30_tarzan_jane_jungle_africa   \n",
       "32     31     77              31_race_car_herbie_racing   \n",
       "33     32     75      32_artagnan_musketeer_athos_louis   \n",
       "34     33     69         33_ollie_stan_stan ollie_hardy   \n",
       "35     34     58         34_betty_bimbo_boop_betty boop   \n",
       "36     35     54         35_godzilla_goku_gohan_monster   \n",
       "37     36     54         36_caesar_rome_roman_marcellus   \n",
       "38     37     52        37_president_bush_nixon_kennedy   \n",
       "39     38     51        38_school_teacher_student_pupil   \n",
       "40     39     50             39_rocky_fight_tommy_match   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [man, kill, make, try, time, life, friend, new...   \n",
       "1   [love, father, family, marry, life, son, come,...   \n",
       "2   [kill, man, house, make, car, try, police, hom...   \n",
       "3   [murder, police, detective, crime, killer, pri...   \n",
       "4   [ho, li, master, man, china, wong, kill, chine...   \n",
       "5   [juan, family, miguel, love, father, man, luis...   \n",
       "6   [earth, scientist, planet, human, alien, space...   \n",
       "7   [confederate, town, union, man, war, sheriff, ...   \n",
       "8   [jean, paris, pierre, marie, love, julien, ant...   \n",
       "9   [german, nazi, hitler, war, berlin, germany, v...   \n",
       "10  [earth, ship, planet, alien, space, human, cre...   \n",
       "11  [ship, pirate, island, boat, captain, shark, c...   \n",
       "12  [ivan, russian, soviet, moscow, alexei, russia...   \n",
       "13  [soldier, man, order, officer, command, submar...   \n",
       "14  [bug, daffy, elmer, porky, duck, rabbit, carto...   \n",
       "15  [vampire, ghost, group, werewolf, daninsky, bl...   \n",
       "16  [team, game, player, coach, play, baseball, le...   \n",
       "17  [samurai, rider, keroro, kill, sakura, attack,...   \n",
       "18  [tom, jerry, spike, mouse, cat, run, tail, gra...   \n",
       "19  [prince, king, arthur, princess, queen, robin,...   \n",
       "20  [santa, christmas, scrooge, claus, santa claus...   \n",
       "21  [stooge, moe, curly, shemp, larry, moe larry, ...   \n",
       "22  [african, africa, south, xan, apartheid, mande...   \n",
       "23  [charlie, charlie brown, brown, snoopy, charle...   \n",
       "24  [israeli, israel, palestinian, ashraf, war, je...   \n",
       "25  [college, school, sorority, student, high scho...   \n",
       "26  [donald, mickey, pluto, pete, minnie, goofy, d...   \n",
       "27  [kenji, itsuki, yumi, tokyo, school, kyoko, to...   \n",
       "28  [dragon, king, sword, kill, fantaghirò, prince...   \n",
       "29  [panther, pink, pink panther, horse, man, litt...   \n",
       "30  [yakuza, tokyo, japan, father, kojima, tsuda, ...   \n",
       "31  [tarzan, jane, jungle, africa, animal, ape, go...   \n",
       "32  [race, car, herbie, racing, racer, win, driver...   \n",
       "33  [artagnan, musketeer, athos, louis, king, rich...   \n",
       "34  [ollie, stan, stan ollie, hardy, laurel, laure...   \n",
       "35  [betty, bimbo, boop, betty boop, grampy, betty...   \n",
       "36  [godzilla, goku, gohan, monster, vegeta, picco...   \n",
       "37  [caesar, rome, roman, marcellus, cleopatra, ca...   \n",
       "38  [president, bush, nixon, kennedy, campaign, fr...   \n",
       "39  [school, teacher, student, pupil, education, h...   \n",
       "40  [rocky, fight, tommy, match, boxing, fighter, ...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [backwoodsman name adam pontipee new bride mil...  \n",
       "1   [young widow commit suicide compel forego mode...  \n",
       "2   [open michelle mancini drive night storm reali...  \n",
       "3   [psychotic killer garland red lynch use campai...  \n",
       "4   [plot|date\"farewell concubine study notes\">{{c...  \n",
       "5   [juan oliver want make good impression new job...  \n",
       "6   [distant future war human race alien know gami...  \n",
       "7   [set state virginia american civil war james s...  \n",
       "8   [\" feel go life like american tourist many tow...  \n",
       "9   [world war ii wehrmacht colonel claus von stau...  \n",
       "10  [commercial tow spaceship nostromo return trip...  \n",
       "11  [plot jim hawkins young boy live mother englan...  \n",
       "12  [begin main character ivan yermakov interview ...  \n",
       "13  [plot begin summary ally struggle stop u boat ...  \n",
       "14  [hollywood home bug bunny interview tv show pe...  \n",
       "15  [knockabout english comedy spoof hammer series...  \n",
       "16  [chronicle journey 1980 us olympic men ice hoc...  \n",
       "17  [april 1 2011 kaman rider ooo find battle thre...  \n",
       "18  [tom acquire book catch mice rest cartoon take...  \n",
       "19  [follow cinderella beautiful girl force chore ...  \n",
       "20  [eight year go since divorce father scott calv...  \n",
       "21  [stooge janitor doctor office work night shift...  \n",
       "22  [follow news depict demolition slum east londo...  \n",
       "23  [special begin charlie brown sit bench lunch t...  \n",
       "24  [noam young israeli reservist work checkpoint ...  \n",
       "25  [set college u.s.a center jake embittered ex h...  \n",
       "26  [black pete walk camp inspect hmm camp sure pe...  \n",
       "27  [hiroko watanabe live kobe lose fiancé itsuki ...  \n",
       "28  [take place forest sidhe follow princess alora...  \n",
       "29  [pink panther set camp night serve dish contai...  \n",
       "30  [follow life kazama family tokyo 30th year shō...  \n",
       "31  [open flashback tarzan ape establish back afri...  \n",
       "32  [stars dean jones return champion race car dri...  \n",
       "33  [d'artagnan inexperienced gascon youth travel ...  \n",
       "34  [stan ollie last six buck call lift job agency...  \n",
       "35  [bimbo show betty door assistant help betty mo...  \n",
       "36  [1992 united nations establish united nations ...  \n",
       "37  [open 48 b.c shortly battle pharsalus julius c...  \n",
       "38  [series news report document role richard nixo...  \n",
       "39  [set danish boy boarding school one boy bo dev...  \n",
       "40  [four half year since win world heavyweight ti...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After refining the topics, we associate each summary with its corresponding topic:\n",
    "- **Topic ID**: A numeric identifier for the topic.  \n",
    "- **Topic Name**: A descriptive label that summarizes the topic's main theme.  \n",
    "\n",
    "The updated dataset is saved, with each summary linked to its topic, allowing for further exploration and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = {\n",
    "    -1: \"Unclassified\",\n",
    "    0: \"Love & Family\",\n",
    "    1: \"Crime\",\n",
    "    2: \"Investigation\",\n",
    "    3: \"Martial Arts\",\n",
    "    4: \"Family Drama\",\n",
    "    5: \"Sci-Fi Earth\",\n",
    "    6: \"Civil War\",\n",
    "    7: \"French Life\",\n",
    "    8: \"WWII\",\n",
    "    9: \"Space\",\n",
    "    10: \"Pirates\",\n",
    "    11: \"USSR\",\n",
    "    12: \"Soldiers\",\n",
    "    13: \"Cartoons\",\n",
    "    14: \"Monsters\",\n",
    "    15: \"Sports\",\n",
    "    16: \"Samurai\",\n",
    "    17: \"Tom & Jerry\",\n",
    "    18: \"Royalty\",\n",
    "    19: \"Christmas\",\n",
    "    20: \"Stooges\",\n",
    "    21: \"Africa\",\n",
    "    22: \"Charlie Brown\",\n",
    "    23: \"Middle East\",\n",
    "    24: \"College\",\n",
    "    25: \"Disney\",\n",
    "    26: \"Tokyo Life\",\n",
    "    27: \"Fantasy\",\n",
    "    28: \"Pink Panther\",\n",
    "    29: \"Yakuza\",\n",
    "    30: \"Jungle\",\n",
    "    31: \"Racing\",\n",
    "    32: \"Musketeers\",\n",
    "    33: \"Laurel & Hardy\",\n",
    "    34: \"Betty Boop\",\n",
    "    35: \"Godzilla\",\n",
    "    36: \"Roman Empire\",\n",
    "    37: \"Politics\",\n",
    "    38: \"School Life\",\n",
    "    39: \"Boxing\"\n",
    "}\n",
    "\n",
    "topic_model.set_topic_labels(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>CustomName</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>20926</td>\n",
       "      <td>-1_man_kill_make_try</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>[man, kill, make, try, time, life, friend, new...</td>\n",
       "      <td>[backwoodsman name adam pontipee new bride mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7433</td>\n",
       "      <td>0_love_father_family_marry</td>\n",
       "      <td>Love &amp; Family</td>\n",
       "      <td>[love, father, family, marry, life, son, come,...</td>\n",
       "      <td>[young widow commit suicide compel forego mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>1_kill_man_house_make</td>\n",
       "      <td>Crime</td>\n",
       "      <td>[kill, man, house, make, car, try, police, hom...</td>\n",
       "      <td>[open michelle mancini drive night storm reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1384</td>\n",
       "      <td>2_murder_police_detective_crime</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>[murder, police, detective, crime, killer, pri...</td>\n",
       "      <td>[psychotic killer garland red lynch use campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>3_ho_li_master_man</td>\n",
       "      <td>Martial Arts</td>\n",
       "      <td>[ho, li, master, man, china, wong, kill, chine...</td>\n",
       "      <td>[plot|date\"farewell concubine study notes\"&gt;{{c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>673</td>\n",
       "      <td>4_juan_family_miguel_love</td>\n",
       "      <td>Family Drama</td>\n",
       "      <td>[juan, family, miguel, love, father, man, luis...</td>\n",
       "      <td>[juan oliver want make good impression new job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>638</td>\n",
       "      <td>5_earth_scientist_planet_human</td>\n",
       "      <td>Sci-Fi Earth</td>\n",
       "      <td>[earth, scientist, planet, human, alien, space...</td>\n",
       "      <td>[distant future war human race alien know gami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>477</td>\n",
       "      <td>6_confederate_town_union_man</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>[confederate, town, union, man, war, sheriff, ...</td>\n",
       "      <td>[set state virginia american civil war james s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>396</td>\n",
       "      <td>7_jean_paris_pierre_marie</td>\n",
       "      <td>French Life</td>\n",
       "      <td>[jean, paris, pierre, marie, love, julien, ant...</td>\n",
       "      <td>[\" feel go life like american tourist many tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>8_german_nazi_hitler_war</td>\n",
       "      <td>WWII</td>\n",
       "      <td>[german, nazi, hitler, war, berlin, germany, v...</td>\n",
       "      <td>[world war ii wehrmacht colonel claus von stau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>352</td>\n",
       "      <td>9_earth_ship_planet_alien</td>\n",
       "      <td>Space</td>\n",
       "      <td>[earth, ship, planet, alien, space, human, cre...</td>\n",
       "      <td>[commercial tow spaceship nostromo return trip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>286</td>\n",
       "      <td>10_ship_pirate_island_boat</td>\n",
       "      <td>Pirates</td>\n",
       "      <td>[ship, pirate, island, boat, captain, shark, c...</td>\n",
       "      <td>[plot jim hawkins young boy live mother englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>227</td>\n",
       "      <td>11_ivan_russian_soviet_moscow</td>\n",
       "      <td>USSR</td>\n",
       "      <td>[ivan, russian, soviet, moscow, alexei, russia...</td>\n",
       "      <td>[begin main character ivan yermakov interview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>224</td>\n",
       "      <td>12_soldier_man_order_officer</td>\n",
       "      <td>Soldiers</td>\n",
       "      <td>[soldier, man, order, officer, command, submar...</td>\n",
       "      <td>[plot begin summary ally struggle stop u boat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>219</td>\n",
       "      <td>13_bug_daffy_elmer_porky</td>\n",
       "      <td>Cartoons</td>\n",
       "      <td>[bug, daffy, elmer, porky, duck, rabbit, carto...</td>\n",
       "      <td>[hollywood home bug bunny interview tv show pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>217</td>\n",
       "      <td>14_vampire_ghost_group_werewolf</td>\n",
       "      <td>Monsters</td>\n",
       "      <td>[vampire, ghost, group, werewolf, daninsky, bl...</td>\n",
       "      <td>[knockabout english comedy spoof hammer series...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>211</td>\n",
       "      <td>15_team_game_player_coach</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[team, game, player, coach, play, baseball, le...</td>\n",
       "      <td>[chronicle journey 1980 us olympic men ice hoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>181</td>\n",
       "      <td>16_samurai_rider_keroro_kill</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>[samurai, rider, keroro, kill, sakura, attack,...</td>\n",
       "      <td>[april 1 2011 kaman rider ooo find battle thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>17_tom_jerry_spike_mouse</td>\n",
       "      <td>Tom &amp; Jerry</td>\n",
       "      <td>[tom, jerry, spike, mouse, cat, run, tail, gra...</td>\n",
       "      <td>[tom acquire book catch mice rest cartoon take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>18_prince_king_arthur_princess</td>\n",
       "      <td>Royalty</td>\n",
       "      <td>[prince, king, arthur, princess, queen, robin,...</td>\n",
       "      <td>[follow cinderella beautiful girl force chore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>150</td>\n",
       "      <td>19_santa_christmas_scrooge_claus</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>[santa, christmas, scrooge, claus, santa claus...</td>\n",
       "      <td>[eight year go since divorce father scott calv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>146</td>\n",
       "      <td>20_stooge_moe_curly_shemp</td>\n",
       "      <td>Stooges</td>\n",
       "      <td>[stooge, moe, curly, shemp, larry, moe larry, ...</td>\n",
       "      <td>[stooge janitor doctor office work night shift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>134</td>\n",
       "      <td>21_african_africa_south_xan</td>\n",
       "      <td>Africa</td>\n",
       "      <td>[african, africa, south, xan, apartheid, mande...</td>\n",
       "      <td>[follow news depict demolition slum east londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>108</td>\n",
       "      <td>22_charlie_charlie brown_brown_snoopy</td>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>[charlie, charlie brown, brown, snoopy, charle...</td>\n",
       "      <td>[special begin charlie brown sit bench lunch t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>104</td>\n",
       "      <td>23_israeli_israel_palestinian_ashraf</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>[israeli, israel, palestinian, ashraf, war, je...</td>\n",
       "      <td>[noam young israeli reservist work checkpoint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>97</td>\n",
       "      <td>24_college_school_sorority_student</td>\n",
       "      <td>College</td>\n",
       "      <td>[college, school, sorority, student, high scho...</td>\n",
       "      <td>[set college u.s.a center jake embittered ex h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>25_donald_mickey_pluto_pete</td>\n",
       "      <td>Disney</td>\n",
       "      <td>[donald, mickey, pluto, pete, minnie, goofy, d...</td>\n",
       "      <td>[black pete walk camp inspect hmm camp sure pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>26_kenji_itsuki_yumi_tokyo</td>\n",
       "      <td>Tokyo Life</td>\n",
       "      <td>[kenji, itsuki, yumi, tokyo, school, kyoko, to...</td>\n",
       "      <td>[hiroko watanabe live kobe lose fiancé itsuki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>85</td>\n",
       "      <td>27_dragon_king_sword_kill</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>[dragon, king, sword, kill, fantaghirò, prince...</td>\n",
       "      <td>[take place forest sidhe follow princess alora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>84</td>\n",
       "      <td>28_panther_pink_pink panther_horse</td>\n",
       "      <td>Pink Panther</td>\n",
       "      <td>[panther, pink, pink panther, horse, man, litt...</td>\n",
       "      <td>[pink panther set camp night serve dish contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>29_yakuza_tokyo_japan_father</td>\n",
       "      <td>Yakuza</td>\n",
       "      <td>[yakuza, tokyo, japan, father, kojima, tsuda, ...</td>\n",
       "      <td>[follow life kazama family tokyo 30th year shō...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>30_tarzan_jane_jungle_africa</td>\n",
       "      <td>Jungle</td>\n",
       "      <td>[tarzan, jane, jungle, africa, animal, ape, go...</td>\n",
       "      <td>[open flashback tarzan ape establish back afri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>77</td>\n",
       "      <td>31_race_car_herbie_racing</td>\n",
       "      <td>Racing</td>\n",
       "      <td>[race, car, herbie, racing, racer, win, driver...</td>\n",
       "      <td>[stars dean jones return champion race car dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>32_artagnan_musketeer_athos_louis</td>\n",
       "      <td>Musketeers</td>\n",
       "      <td>[artagnan, musketeer, athos, louis, king, rich...</td>\n",
       "      <td>[d'artagnan inexperienced gascon youth travel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>69</td>\n",
       "      <td>33_ollie_stan_stan ollie_hardy</td>\n",
       "      <td>Laurel &amp; Hardy</td>\n",
       "      <td>[ollie, stan, stan ollie, hardy, laurel, laure...</td>\n",
       "      <td>[stan ollie last six buck call lift job agency...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>34_betty_bimbo_boop_betty boop</td>\n",
       "      <td>Betty Boop</td>\n",
       "      <td>[betty, bimbo, boop, betty boop, grampy, betty...</td>\n",
       "      <td>[bimbo show betty door assistant help betty mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>54</td>\n",
       "      <td>35_godzilla_goku_gohan_monster</td>\n",
       "      <td>Godzilla</td>\n",
       "      <td>[godzilla, goku, gohan, monster, vegeta, picco...</td>\n",
       "      <td>[1992 united nations establish united nations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>36_caesar_rome_roman_marcellus</td>\n",
       "      <td>Roman Empire</td>\n",
       "      <td>[caesar, rome, roman, marcellus, cleopatra, ca...</td>\n",
       "      <td>[open 48 b.c shortly battle pharsalus julius c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>37_president_bush_nixon_kennedy</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[president, bush, nixon, kennedy, campaign, fr...</td>\n",
       "      <td>[series news report document role richard nixo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38_school_teacher_student_pupil</td>\n",
       "      <td>School Life</td>\n",
       "      <td>[school, teacher, student, pupil, education, h...</td>\n",
       "      <td>[set danish boy boarding school one boy bo dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>39_rocky_fight_tommy_match</td>\n",
       "      <td>Boxing</td>\n",
       "      <td>[rocky, fight, tommy, match, boxing, fighter, ...</td>\n",
       "      <td>[four half year since win world heavyweight ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                   Name      CustomName  \\\n",
       "0      -1  20926                   -1_man_kill_make_try    Unclassified   \n",
       "1       0   7433             0_love_father_family_marry   Love & Family   \n",
       "2       1   4606                  1_kill_man_house_make           Crime   \n",
       "3       2   1384        2_murder_police_detective_crime   Investigation   \n",
       "4       3   1165                     3_ho_li_master_man    Martial Arts   \n",
       "5       4    673              4_juan_family_miguel_love    Family Drama   \n",
       "6       5    638         5_earth_scientist_planet_human    Sci-Fi Earth   \n",
       "7       6    477           6_confederate_town_union_man       Civil War   \n",
       "8       7    396              7_jean_paris_pierre_marie     French Life   \n",
       "9       8    356               8_german_nazi_hitler_war            WWII   \n",
       "10      9    352              9_earth_ship_planet_alien           Space   \n",
       "11     10    286             10_ship_pirate_island_boat         Pirates   \n",
       "12     11    227          11_ivan_russian_soviet_moscow            USSR   \n",
       "13     12    224           12_soldier_man_order_officer        Soldiers   \n",
       "14     13    219               13_bug_daffy_elmer_porky        Cartoons   \n",
       "15     14    217        14_vampire_ghost_group_werewolf        Monsters   \n",
       "16     15    211              15_team_game_player_coach          Sports   \n",
       "17     16    181           16_samurai_rider_keroro_kill         Samurai   \n",
       "18     17    158               17_tom_jerry_spike_mouse     Tom & Jerry   \n",
       "19     18    152         18_prince_king_arthur_princess         Royalty   \n",
       "20     19    150       19_santa_christmas_scrooge_claus       Christmas   \n",
       "21     20    146              20_stooge_moe_curly_shemp         Stooges   \n",
       "22     21    134            21_african_africa_south_xan          Africa   \n",
       "23     22    108  22_charlie_charlie brown_brown_snoopy   Charlie Brown   \n",
       "24     23    104   23_israeli_israel_palestinian_ashraf     Middle East   \n",
       "25     24     97     24_college_school_sorority_student         College   \n",
       "26     25     92            25_donald_mickey_pluto_pete          Disney   \n",
       "27     26     91             26_kenji_itsuki_yumi_tokyo      Tokyo Life   \n",
       "28     27     85              27_dragon_king_sword_kill         Fantasy   \n",
       "29     28     84     28_panther_pink_pink panther_horse    Pink Panther   \n",
       "30     29     83           29_yakuza_tokyo_japan_father          Yakuza   \n",
       "31     30     80           30_tarzan_jane_jungle_africa          Jungle   \n",
       "32     31     77              31_race_car_herbie_racing          Racing   \n",
       "33     32     75      32_artagnan_musketeer_athos_louis      Musketeers   \n",
       "34     33     69         33_ollie_stan_stan ollie_hardy  Laurel & Hardy   \n",
       "35     34     58         34_betty_bimbo_boop_betty boop      Betty Boop   \n",
       "36     35     54         35_godzilla_goku_gohan_monster        Godzilla   \n",
       "37     36     54         36_caesar_rome_roman_marcellus    Roman Empire   \n",
       "38     37     52        37_president_bush_nixon_kennedy        Politics   \n",
       "39     38     51        38_school_teacher_student_pupil     School Life   \n",
       "40     39     50             39_rocky_fight_tommy_match          Boxing   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [man, kill, make, try, time, life, friend, new...   \n",
       "1   [love, father, family, marry, life, son, come,...   \n",
       "2   [kill, man, house, make, car, try, police, hom...   \n",
       "3   [murder, police, detective, crime, killer, pri...   \n",
       "4   [ho, li, master, man, china, wong, kill, chine...   \n",
       "5   [juan, family, miguel, love, father, man, luis...   \n",
       "6   [earth, scientist, planet, human, alien, space...   \n",
       "7   [confederate, town, union, man, war, sheriff, ...   \n",
       "8   [jean, paris, pierre, marie, love, julien, ant...   \n",
       "9   [german, nazi, hitler, war, berlin, germany, v...   \n",
       "10  [earth, ship, planet, alien, space, human, cre...   \n",
       "11  [ship, pirate, island, boat, captain, shark, c...   \n",
       "12  [ivan, russian, soviet, moscow, alexei, russia...   \n",
       "13  [soldier, man, order, officer, command, submar...   \n",
       "14  [bug, daffy, elmer, porky, duck, rabbit, carto...   \n",
       "15  [vampire, ghost, group, werewolf, daninsky, bl...   \n",
       "16  [team, game, player, coach, play, baseball, le...   \n",
       "17  [samurai, rider, keroro, kill, sakura, attack,...   \n",
       "18  [tom, jerry, spike, mouse, cat, run, tail, gra...   \n",
       "19  [prince, king, arthur, princess, queen, robin,...   \n",
       "20  [santa, christmas, scrooge, claus, santa claus...   \n",
       "21  [stooge, moe, curly, shemp, larry, moe larry, ...   \n",
       "22  [african, africa, south, xan, apartheid, mande...   \n",
       "23  [charlie, charlie brown, brown, snoopy, charle...   \n",
       "24  [israeli, israel, palestinian, ashraf, war, je...   \n",
       "25  [college, school, sorority, student, high scho...   \n",
       "26  [donald, mickey, pluto, pete, minnie, goofy, d...   \n",
       "27  [kenji, itsuki, yumi, tokyo, school, kyoko, to...   \n",
       "28  [dragon, king, sword, kill, fantaghirò, prince...   \n",
       "29  [panther, pink, pink panther, horse, man, litt...   \n",
       "30  [yakuza, tokyo, japan, father, kojima, tsuda, ...   \n",
       "31  [tarzan, jane, jungle, africa, animal, ape, go...   \n",
       "32  [race, car, herbie, racing, racer, win, driver...   \n",
       "33  [artagnan, musketeer, athos, louis, king, rich...   \n",
       "34  [ollie, stan, stan ollie, hardy, laurel, laure...   \n",
       "35  [betty, bimbo, boop, betty boop, grampy, betty...   \n",
       "36  [godzilla, goku, gohan, monster, vegeta, picco...   \n",
       "37  [caesar, rome, roman, marcellus, cleopatra, ca...   \n",
       "38  [president, bush, nixon, kennedy, campaign, fr...   \n",
       "39  [school, teacher, student, pupil, education, h...   \n",
       "40  [rocky, fight, tommy, match, boxing, fighter, ...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [backwoodsman name adam pontipee new bride mil...  \n",
       "1   [young widow commit suicide compel forego mode...  \n",
       "2   [open michelle mancini drive night storm reali...  \n",
       "3   [psychotic killer garland red lynch use campai...  \n",
       "4   [plot|date\"farewell concubine study notes\">{{c...  \n",
       "5   [juan oliver want make good impression new job...  \n",
       "6   [distant future war human race alien know gami...  \n",
       "7   [set state virginia american civil war james s...  \n",
       "8   [\" feel go life like american tourist many tow...  \n",
       "9   [world war ii wehrmacht colonel claus von stau...  \n",
       "10  [commercial tow spaceship nostromo return trip...  \n",
       "11  [plot jim hawkins young boy live mother englan...  \n",
       "12  [begin main character ivan yermakov interview ...  \n",
       "13  [plot begin summary ally struggle stop u boat ...  \n",
       "14  [hollywood home bug bunny interview tv show pe...  \n",
       "15  [knockabout english comedy spoof hammer series...  \n",
       "16  [chronicle journey 1980 us olympic men ice hoc...  \n",
       "17  [april 1 2011 kaman rider ooo find battle thre...  \n",
       "18  [tom acquire book catch mice rest cartoon take...  \n",
       "19  [follow cinderella beautiful girl force chore ...  \n",
       "20  [eight year go since divorce father scott calv...  \n",
       "21  [stooge janitor doctor office work night shift...  \n",
       "22  [follow news depict demolition slum east londo...  \n",
       "23  [special begin charlie brown sit bench lunch t...  \n",
       "24  [noam young israeli reservist work checkpoint ...  \n",
       "25  [set college u.s.a center jake embittered ex h...  \n",
       "26  [black pete walk camp inspect hmm camp sure pe...  \n",
       "27  [hiroko watanabe live kobe lose fiancé itsuki ...  \n",
       "28  [take place forest sidhe follow princess alora...  \n",
       "29  [pink panther set camp night serve dish contai...  \n",
       "30  [follow life kazama family tokyo 30th year shō...  \n",
       "31  [open flashback tarzan ape establish back afri...  \n",
       "32  [stars dean jones return champion race car dri...  \n",
       "33  [d'artagnan inexperienced gascon youth travel ...  \n",
       "34  [stan ollie last six buck call lift job agency...  \n",
       "35  [bimbo show betty door assistant help betty mo...  \n",
       "36  [1992 united nations establish united nations ...  \n",
       "37  [open 48 b.c shortly battle pharsalus julius c...  \n",
       "38  [series news report document role richard nixo...  \n",
       "39  [set danish boy boarding school one boy bo dev...  \n",
       "40  [four half year since win world heavyweight ti...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 17:01:37,616 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "source": [
    "# Save the merged model\n",
    "topic_model.save(\"topic_model_merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect each summary to the topic with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(\"topic_model_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1315/1315 [36:55<00:00,  1.68s/it] \n"
     ]
    }
   ],
   "source": [
    "# Get the topics for each summary\n",
    "topics, probabilities = topic_model.transform(docs)\n",
    "\n",
    "# Add the topics to the dataframe\n",
    "df_cleaned_summaries[\"topic\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the names of the topics\n",
    "df_cleaned_summaries[\"topic_name\"] = df_cleaned_summaries[\"topic\"].map(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "df_cleaned_summaries.to_csv(\"../../data/cultureData/topicModelData/summaries_with_topics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
