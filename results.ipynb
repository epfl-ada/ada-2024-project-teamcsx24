{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules to import\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies successfully loaded\n",
      "Characters successfully loaded\n",
      "Clusters successfully loaded\n",
      "Summaries successfully loaded\n",
      "Dates successfully converted\n",
      "Build of countries dictionnary...\n",
      "Build of languages dictionnary...\n",
      "Build of genres dictionnary...\n",
      "Build of actors dictionnary...\n",
      "Build of character dictionnary...\n",
      "Build of movies dictionnary...\n",
      "Dictionnaries successfully saved\n",
      "Saved movies_cleaned to data/cleanData/movies_cleaned.csv\n",
      "Saved characters_cleaned to data/cleanData/characters_cleaned.csv\n",
      "Saved character_clusters_cleaned to data/cleanData/character_clusters_cleaned.csv\n",
      "Saved summaries_cleaned to data/cleanData/summaries_cleaned.csv\n",
      "Datasets successfully saved\n",
      "Data cleaning successfully done\n"
     ]
    }
   ],
   "source": [
    "# Execute dataCleaning.py\n",
    "# This script create dictionaries of freebase_id, convert date to datetime object, transform our columns\n",
    "\n",
    "%run src/scripts/dataCleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataloader function\n",
    "path = 'src/data'\n",
    "sys.path.append(path)\n",
    "from dataLoader import loadDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnau\\OneDrive\\Documents\\Scolarité EPFL\\ADA\\ada-2024-project-teamcsx24\\src/data\\dataLoader.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[columns_to_convert] = df[columns_to_convert].applymap(eval)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%Y-%m-%d %H:%M:%S\": \"-04:00\", at position 2255. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m path_to_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/cleanData/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m df_movies \u001b[38;5;241m=\u001b[39m loadDataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovies\u001b[39m\u001b[38;5;124m'\u001b[39m, path_to_directory)\n\u001b[1;32m----> 4\u001b[0m df_characters \u001b[38;5;241m=\u001b[39m loadDataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacters\u001b[39m\u001b[38;5;124m'\u001b[39m, path_to_directory)\n\u001b[0;32m      5\u001b[0m df_clusters \u001b[38;5;241m=\u001b[39m loadDataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters\u001b[39m\u001b[38;5;124m'\u001b[39m, path_to_directory)\n\u001b[0;32m      6\u001b[0m df_summaries \u001b[38;5;241m=\u001b[39m loadDataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummaries\u001b[39m\u001b[38;5;124m'\u001b[39m, path_to_directory)\n",
      "File \u001b[1;32mc:\\Users\\arnau\\OneDrive\\Documents\\Scolarité EPFL\\ADA\\ada-2024-project-teamcsx24\\src/data\\dataLoader.py:17\u001b[0m, in \u001b[0;36mloadDataframe\u001b[1;34m(name, path_to_directory)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacters\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     15\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path_to_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacters_cleaned.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbirth_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbirth_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m convert_listlike(arg\u001b[38;5;241m.\u001b[39m_values, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:587\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%Y-%m-%d %H:%M:%S\": \"-04:00\", at position 2255. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "path_to_directory = 'data/cleanData/'\n",
    "df_movies = loadDataframe('movies', path_to_directory)\n",
    "df_characters = loadDataframe('characters', path_to_directory)\n",
    "df_clusters = loadDataframe('clusters', path_to_directory)\n",
    "df_summaries = loadDataframe('summaries', path_to_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data statistics overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_movies\u001b[38;5;241m.\u001b[39minfo())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_movies' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_movies.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.174100e+04</td>\n",
       "      <td>8.401000e+03</td>\n",
       "      <td>6.129100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.740784e+07</td>\n",
       "      <td>4.799363e+07</td>\n",
       "      <td>1.118192e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098791e+07</td>\n",
       "      <td>1.121753e+08</td>\n",
       "      <td>4.360070e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.300000e+02</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.323695e+06</td>\n",
       "      <td>2.083193e+06</td>\n",
       "      <td>8.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.777899e+07</td>\n",
       "      <td>1.063969e+07</td>\n",
       "      <td>9.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.715573e+07</td>\n",
       "      <td>4.071696e+07</td>\n",
       "      <td>1.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.750192e+07</td>\n",
       "      <td>2.782275e+09</td>\n",
       "      <td>1.079281e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wiki_id       revenue       runtime\n",
       "count  8.174100e+04  8.401000e+03  6.129100e+04\n",
       "mean   1.740784e+07  4.799363e+07  1.118192e+02\n",
       "std    1.098791e+07  1.121753e+08  4.360070e+03\n",
       "min    3.300000e+02  1.000000e+04  0.000000e+00\n",
       "25%    7.323695e+06  2.083193e+06  8.100000e+01\n",
       "50%    1.777899e+07  1.063969e+07  9.300000e+01\n",
       "75%    2.715573e+07  4.071696e+07  1.060000e+02\n",
       "max    3.750192e+07  2.782275e+09  1.079281e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wiki_id                  0.000000\n",
       "freebase_id              0.000000\n",
       "original_title           0.000000\n",
       "release_date             0.084437\n",
       "revenue                  0.897224\n",
       "runtime                  0.250180\n",
       "languages                0.000000\n",
       "countries                0.000000\n",
       "genres                   0.000000\n",
       "countries_freebase_id    0.000000\n",
       "languages_freebase_id    0.000000\n",
       "genres_freebase_id       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non null values proportion\n",
    "df_movies.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that we are interested in are the following:\n",
    "- 'release_date' : more than 80% of the movies have a release date\n",
    "- 'genre' : 100% of the movies have a genre\n",
    "- 'countries' : 100% of the movies have a country\n",
    "- 'languages' : 100% of the movies have a language\n",
    "\n",
    "So we have a large amount of non null values that we can use to make our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_venn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_venn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m venn2\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintersectionWikiId\u001b[39m(df1, df2, name1, name2, id_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Ids extraction from each DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     ids1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df1[id_column]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib_venn'"
     ]
    }
   ],
   "source": [
    "from matplotlib_venn import venn2\n",
    "\n",
    "def intersectionWikiId(df1, df2, name1, name2, id_column='id'):\n",
    "    # Ids extraction from each DataFrame\n",
    "    ids1 = set(df1[id_column].unique())\n",
    "    ids2 = set(df2[id_column].unique())\n",
    "    \n",
    "    # Compute intersection and differences\n",
    "    intersection = ids1 & ids2\n",
    "    only_df1 = ids1 - ids2\n",
    "    only_df2 = ids2 - ids1\n",
    "    \n",
    "    # Count elements\n",
    "    count_intersection = len(intersection)\n",
    "    count_only_df1 = len(only_df1)\n",
    "    count_only_df2 = len(only_df2)\n",
    "    total = count_intersection + count_only_df1 + count_only_df2\n",
    "\n",
    "    # Venn diagram\n",
    "    venn = venn2(subsets=(1, 1, 1), set_labels=(name1, name2))\n",
    "    \n",
    "    # Add counts\n",
    "    venn.get_label_by_id('10').set_text(f'{count_only_df1}')\n",
    "    venn.get_label_by_id('01').set_text(f'{count_only_df2}')\n",
    "    venn.get_label_by_id('11').set_text(f'{count_intersection}')\n",
    "    \n",
    "    plt.title(\"Intersection between \" + name1 + \" and \" + name2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intersectionWikiId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mintersectionWikiId\u001b[49m(df_movies, df_characters, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovies\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCharacters\u001b[39m\u001b[38;5;124m'\u001b[39m, id_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'intersectionWikiId' is not defined"
     ]
    }
   ],
   "source": [
    "intersectionWikiId(df_movies, df_characters, 'Movies', 'Characters', id_column='wiki_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Culture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersectionWikiId(df_movies, df_summaries, 'Movies', 'Summaries', id_column='wiki_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
